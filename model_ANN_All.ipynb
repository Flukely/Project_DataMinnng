{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# นำเข้าข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GRADUATEYEAR     STUDENTID  GPAgraduate\n",
      "count    343.000000  3.430000e+02   343.000000\n",
      "mean    2564.303207  1.002616e+08     2.610554\n",
      "std        1.389672  1.621539e+04     0.413158\n",
      "min     2562.000000  1.002056e+08     2.000000\n",
      "25%     2563.000000  1.002492e+08     2.310000\n",
      "50%     2564.000000  1.002611e+08     2.540000\n",
      "75%     2566.000000  1.002712e+08     2.815000\n",
      "max     2566.000000  1.002872e+08     3.970000\n",
      "['GRADUATEYEAR', 'STUDENTID', 'CalculusforScience', 'FundamentalsOfProgramming', 'HistoryAndDevelopmentOfComputerTechnology', 'MathematicsForScience', 'ObjectOrientedProgramming', 'ThaiLanguageSkills', 'PoliticsEconomyandSociety', 'PhilosophyOfScience', 'ManAndEnvironment', 'LifeSkills', 'LanguageSocietyAndCulture', 'EnglishCriticalReadingForEffectiveCommunication', 'ComputerArchitecture', 'DataStructure', 'DatabaseSystems', 'DiscreteMathematicsForComputerScience', 'LinearAlgebraAndApplications', 'OperatingSystems', 'StatisticalAnalysis', 'EnglishWritingForEffectiveCommunication', 'AlgorithmDesignandAnalysis', 'ArtificialIntelligence', 'ComputerNetworkAndDataCommunication', 'SoftwareEngineering', 'DataMiningTechniques', 'MobileApplicationDevelopment', 'MultimediaAnd WebTechnology', 'SensingAndActuationForInternetOfThings', 'CommunicativeEnglishForAcademicAnalysisInComputerTechnology', 'CommunicativeEnglishForResearchPresentationInComputerTechnology', 'CommunicativeEnglishForSpecificPurposesInComputerTechnology', 'DataScience', 'DevelopmentalEnglish', 'DigitalImageProcessing', 'DigitalMarketing', 'EnergyAndTechnologyAroundUs', 'FundamentalEnglish', 'FundamentalLawsForQualityOfLife', 'InternetProgramming', 'IntroductionToComputerInformationScience', 'IntroductionToRobotics', 'LifeAndHealth', 'LifePrivacy', 'MultimediaApplicationDevelopment', 'MusicStudiesInThaiCulture', 'ProgrammingLanguages', 'Seminar', 'SpecialTopicsInComputerScience', 'SystemAnalysisAndDesign', 'GPAgraduate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRADUATEYEAR</th>\n",
       "      <th>STUDENTID</th>\n",
       "      <th>CalculusforScience</th>\n",
       "      <th>FundamentalsOfProgramming</th>\n",
       "      <th>HistoryAndDevelopmentOfComputerTechnology</th>\n",
       "      <th>MathematicsForScience</th>\n",
       "      <th>ObjectOrientedProgramming</th>\n",
       "      <th>ThaiLanguageSkills</th>\n",
       "      <th>PoliticsEconomyandSociety</th>\n",
       "      <th>PhilosophyOfScience</th>\n",
       "      <th>...</th>\n",
       "      <th>IntroductionToRobotics</th>\n",
       "      <th>LifeAndHealth</th>\n",
       "      <th>LifePrivacy</th>\n",
       "      <th>MultimediaApplicationDevelopment</th>\n",
       "      <th>MusicStudiesInThaiCulture</th>\n",
       "      <th>ProgrammingLanguages</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>SpecialTopicsInComputerScience</th>\n",
       "      <th>SystemAnalysisAndDesign</th>\n",
       "      <th>GPAgraduate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562</td>\n",
       "      <td>100205568</td>\n",
       "      <td>D+</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>D</td>\n",
       "      <td>C+</td>\n",
       "      <td>C</td>\n",
       "      <td>C+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2562</td>\n",
       "      <td>100205606</td>\n",
       "      <td>D</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "      <td>100215265</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>D+</td>\n",
       "      <td>C</td>\n",
       "      <td>C+</td>\n",
       "      <td>C+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C+</td>\n",
       "      <td>C</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2562</td>\n",
       "      <td>100225543</td>\n",
       "      <td>F</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>B+</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>C+</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2565</td>\n",
       "      <td>100225544</td>\n",
       "      <td>F</td>\n",
       "      <td>C+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282344</td>\n",
       "      <td>D</td>\n",
       "      <td>D+</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D+</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282356</td>\n",
       "      <td>C+</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B+</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282359</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>D+</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C+</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2566</td>\n",
       "      <td>100282360</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2565</td>\n",
       "      <td>100287192</td>\n",
       "      <td>F</td>\n",
       "      <td>C+</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRADUATEYEAR  STUDENTID CalculusforScience FundamentalsOfProgramming  \\\n",
       "0            2562  100205568                 D+                        B+   \n",
       "1            2562  100205606                  D                        B+   \n",
       "2            2564  100215265                  F                         B   \n",
       "3            2562  100225543                  F                        C+   \n",
       "4            2565  100225544                  F                        C+   \n",
       "..            ...        ...                ...                       ...   \n",
       "338          2566  100282344                  D                        D+   \n",
       "339          2566  100282356                 C+                         C   \n",
       "340          2566  100282359                  C                         C   \n",
       "341          2566  100282360                  D                         C   \n",
       "342          2565  100287192                  F                        C+   \n",
       "\n",
       "    HistoryAndDevelopmentOfComputerTechnology MathematicsForScience  \\\n",
       "0                                         NaN                    C+   \n",
       "1                                         NaN                    D+   \n",
       "2                                         NaN                    D+   \n",
       "3                                         NaN                     F   \n",
       "4                                         NaN                     F   \n",
       "..                                        ...                   ...   \n",
       "338                                         A                     D   \n",
       "339                                         A                     A   \n",
       "340                                         A                    D+   \n",
       "341                                         A                     D   \n",
       "342                                         A                     C   \n",
       "\n",
       "    ObjectOrientedProgramming ThaiLanguageSkills PoliticsEconomyandSociety  \\\n",
       "0                           D                 C+                         C   \n",
       "1                           D                  C                       NaN   \n",
       "2                          D+                  C                        C+   \n",
       "3                           D                 C+                       NaN   \n",
       "4                           C                  B                       NaN   \n",
       "..                        ...                ...                       ...   \n",
       "338                         D                NaN                       NaN   \n",
       "339                        B+                NaN                       NaN   \n",
       "340                         C                NaN                       NaN   \n",
       "341                         A                NaN                       NaN   \n",
       "342                         D                  C                       NaN   \n",
       "\n",
       "    PhilosophyOfScience  ... IntroductionToRobotics LifeAndHealth LifePrivacy  \\\n",
       "0                    C+  ...                    NaN           NaN         NaN   \n",
       "1                    C+  ...                    NaN            B+         NaN   \n",
       "2                    C+  ...                    NaN           NaN         NaN   \n",
       "3                    C+  ...                    NaN           NaN         NaN   \n",
       "4                    C+  ...                      B           NaN         NaN   \n",
       "..                  ...  ...                    ...           ...         ...   \n",
       "338                 NaN  ...                    NaN             A         NaN   \n",
       "339                 NaN  ...                    NaN           NaN         NaN   \n",
       "340                 NaN  ...                    NaN           NaN         NaN   \n",
       "341                 NaN  ...                    NaN           NaN         NaN   \n",
       "342                 NaN  ...                    NaN           NaN         NaN   \n",
       "\n",
       "    MultimediaApplicationDevelopment MusicStudiesInThaiCulture  \\\n",
       "0                                NaN                       NaN   \n",
       "1                                NaN                         C   \n",
       "2                                NaN                       NaN   \n",
       "3                                  B                        B+   \n",
       "4                                NaN                        C+   \n",
       "..                               ...                       ...   \n",
       "338                              NaN                       NaN   \n",
       "339                              NaN                         A   \n",
       "340                              NaN                         A   \n",
       "341                              NaN                       NaN   \n",
       "342                               B+                       NaN   \n",
       "\n",
       "    ProgrammingLanguages Seminar SpecialTopicsInComputerScience  \\\n",
       "0                      D       B                            NaN   \n",
       "1                      D      C+                            NaN   \n",
       "2                      D       B                             C+   \n",
       "3                      D       B                              C   \n",
       "4                      C       B                            NaN   \n",
       "..                   ...     ...                            ...   \n",
       "338                  NaN       A                            NaN   \n",
       "339                  NaN       A                            NaN   \n",
       "340                  NaN       A                            NaN   \n",
       "341                  NaN       A                            NaN   \n",
       "342                  NaN       B                            NaN   \n",
       "\n",
       "    SystemAnalysisAndDesign GPAgraduate  \n",
       "0                        C+        2.10  \n",
       "1                         C        2.00  \n",
       "2                         C        2.01  \n",
       "3                        C+        2.10  \n",
       "4                         C        2.15  \n",
       "..                      ...         ...  \n",
       "338                      D+        2.34  \n",
       "339                      B+        3.19  \n",
       "340                      C+        2.68  \n",
       "341                       C        2.52  \n",
       "342                       C        2.51  \n",
       "\n",
       "[343 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# โหลดข้อมูลจากไฟล์ CSV\n",
    "data = pd.read_csv('DataComsci.csv')  # อ่านข้อมูลจากไฟล์ CSV\n",
    "\n",
    "# ดูตัวอย่างข้อมูล\n",
    "print(data.describe())\n",
    "\n",
    "print(data.columns.tolist())\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 1: เตรียมข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แปลงเกรดเป็นค่าตัวเลข\n",
    "grade_mapping = {'A': 4.0, 'B+': 3.5, 'B': 3.0, 'C+': 2.5, 'C': 2.0, 'D+': 1.5, 'D': 1.0, 'F': 0.0}\n",
    "data.replace(grade_mapping, inplace=True)\n",
    "\n",
    "# แทนค่าที่หายไปด้วยค่าเฉลี่ยของแต่ละคอลัมน์สำหรับคอลัมน์ตัวเลข\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# เลือกฟีเจอร์ที่เกี่ยวข้อง (รายวิชาที่จะใช้ทำนาย GPA)\n",
    "features = [\n",
    "        'CalculusforScience', 'FundamentalsOfProgramming', 'HistoryAndDevelopmentOfComputerTechnology',\n",
    "        'MathematicsForScience', 'ObjectOrientedProgramming', 'ThaiLanguageSkills',\n",
    "        'PoliticsEconomyandSociety', 'PhilosophyOfScience', 'ManAndEnvironment',\n",
    "        'LifeSkills', 'LanguageSocietyAndCulture', 'EnglishCriticalReadingForEffectiveCommunication',\n",
    "        'ComputerArchitecture', 'DataStructure', 'DatabaseSystems',\n",
    "        'DiscreteMathematicsForComputerScience', 'LinearAlgebraAndApplications',\n",
    "        'OperatingSystems', 'StatisticalAnalysis', 'EnglishWritingForEffectiveCommunication',\n",
    "        'AlgorithmDesignandAnalysis', 'ArtificialIntelligence', 'ComputerNetworkAndDataCommunication',\n",
    "        'Seminar', 'SoftwareEngineering', 'DataMiningTechniques', \n",
    "        'MobileApplicationDevelopment', 'MultimediaAnd WebTechnology', \n",
    "        'SensingAndActuationForInternetOfThings','SystemAnalysisAndDesign'\n",
    "]  # แทนที่ด้วยรายชื่อฟีเจอร์ที่คุณต้องการ\n",
    "\n",
    "X = data[features]  # สร้าง DataFrame สำหรับฟีเจอร์\n",
    "\n",
    "# แปลงฟีเจอร์ที่เป็นประเภทข้อความ (categorical) ถ้ามี\n",
    "label_encoders = {}\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    # ลบค่า NaN และตรวจสอบให้แน่ใจว่าคอลัมน์มีประเภทข้อมูลเป็นข้อความอย่างเดียว\n",
    "    if X[col].isnull().all():  # ตรวจสอบว่าคอลัมน์เป็น NaN ทั้งหมด\n",
    "        continue\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))  # แปลงเป็นสตริงเพื่อหลีกเลี่ยงประเภทข้อมูลผสม\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# ตัวแปรเป้าหมาย (GPA)\n",
    "y = data['GPAgraduate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตรวจสอบขนาดของ X และ y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343, 30)\n",
      "(343,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 2: แบ่งข้อมูลเป็นชุดฝึกและชุดทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แบ่งข้อมูลเป็นชุดฝึก (train) และชุดทดสอบ (test) ในสัดส่วน 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ทำการปรับมาตรฐานข้อมูล (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 3: สร้างโมเดล ANN และฝึกสอน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">775</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │           \u001b[38;5;34m775\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,181</span> (4.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,181\u001b[0m (4.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,181</span> (4.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,181\u001b[0m (4.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.7701 - val_loss: 3.6753\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5789 - val_loss: 1.3035\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5418 - val_loss: 0.3578\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2525 - val_loss: 0.2494\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1227 - val_loss: 0.1506\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0772 - val_loss: 0.1179\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0578 - val_loss: 0.0992\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - val_loss: 0.0782\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0318 - val_loss: 0.0649\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0273 - val_loss: 0.0586\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222 - val_loss: 0.0626\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0168 - val_loss: 0.0502\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0189 - val_loss: 0.0572\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0137 - val_loss: 0.0496\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0148 - val_loss: 0.0646\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0165 - val_loss: 0.0633\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - val_loss: 0.0437\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0430\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0097 - val_loss: 0.0303\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0246\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0263\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0278\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0255\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0226\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0288\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0238\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0211\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0208\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0190\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0220\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0216\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0214\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0217\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0188\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0203\n",
      "Epoch 36/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0195\n",
      "Epoch 37/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0225\n",
      "Epoch 38/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0224\n",
      "Epoch 40/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0234\n",
      "Epoch 41/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0241\n",
      "Epoch 42/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0243\n",
      "Epoch 43/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0190\n",
      "Epoch 44/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0168\n",
      "Epoch 45/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0187\n",
      "Epoch 46/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0180\n",
      "Epoch 47/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0184\n",
      "Epoch 48/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0163\n",
      "Epoch 49/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0178\n",
      "Epoch 50/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - val_loss: 0.0186\n",
      "Epoch 51/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0218\n",
      "Epoch 52/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0186\n",
      "Epoch 53/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0191\n",
      "Epoch 54/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0191\n",
      "Epoch 55/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0202\n",
      "Epoch 56/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0185\n",
      "Epoch 57/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3047e-04 - val_loss: 0.0191\n",
      "Epoch 58/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0205\n",
      "Epoch 59/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0181\n",
      "Epoch 60/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0193\n",
      "Epoch 61/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0208\n",
      "Epoch 62/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0180\n",
      "Epoch 63/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0188\n",
      "Epoch 64/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0221\n",
      "Epoch 65/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0181\n",
      "Epoch 66/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0223\n",
      "Epoch 67/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0222\n",
      "Epoch 68/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0193\n",
      "Epoch 69/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0297\n",
      "Epoch 70/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0172\n",
      "Epoch 71/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0166\n",
      "Epoch 72/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0162\n",
      "Epoch 73/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0174\n",
      "Epoch 74/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0206\n",
      "Epoch 75/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0189\n",
      "Epoch 76/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0176\n",
      "Epoch 77/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0167\n",
      "Epoch 78/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0198\n",
      "Epoch 79/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0202\n",
      "Epoch 80/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0190\n",
      "Epoch 81/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0222\n",
      "Epoch 82/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0165\n",
      "Epoch 83/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0215\n",
      "Epoch 84/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0193\n",
      "Epoch 85/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0219\n",
      "Epoch 86/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0190\n",
      "Epoch 87/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7415e-04 - val_loss: 0.0176\n",
      "Epoch 88/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6388e-04 - val_loss: 0.0190\n",
      "Epoch 89/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8891e-04 - val_loss: 0.0192\n",
      "Epoch 90/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - val_loss: 0.0178\n",
      "Epoch 91/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3011e-04 - val_loss: 0.0201\n",
      "Epoch 92/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0202\n",
      "Epoch 93/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0173\n",
      "Epoch 94/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0198\n",
      "Epoch 95/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8102e-04 - val_loss: 0.0189\n",
      "Epoch 96/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0180\n",
      "Epoch 97/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - val_loss: 0.0201\n",
      "Epoch 98/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0214\n",
      "Epoch 99/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0197\n",
      "Epoch 100/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4758e-04 - val_loss: 0.0184\n",
      "Epoch 101/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6976e-04 - val_loss: 0.0211\n",
      "Epoch 102/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0197\n",
      "Epoch 103/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0209\n",
      "Epoch 104/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0187\n",
      "Epoch 105/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0173\n",
      "Epoch 106/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9187e-04 - val_loss: 0.0182\n",
      "Epoch 107/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9816e-04 - val_loss: 0.0204\n",
      "Epoch 108/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.2085e-04 - val_loss: 0.0200\n",
      "Epoch 109/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2204e-04 - val_loss: 0.0209\n",
      "Epoch 110/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0219\n",
      "Epoch 111/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0246\n",
      "Epoch 112/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0224\n",
      "Epoch 113/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0186\n",
      "Epoch 114/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0204\n",
      "Epoch 115/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0193\n",
      "Epoch 116/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0182\n",
      "Epoch 117/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0187\n",
      "Epoch 118/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0163\n",
      "Epoch 119/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - val_loss: 0.0185\n",
      "Epoch 120/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9312e-04 - val_loss: 0.0191\n",
      "Epoch 121/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7209e-04 - val_loss: 0.0190\n",
      "Epoch 122/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3156e-04 - val_loss: 0.0181\n",
      "Epoch 123/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3890e-04 - val_loss: 0.0172\n",
      "Epoch 124/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1487e-04 - val_loss: 0.0188\n",
      "Epoch 125/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8043e-04 - val_loss: 0.0177\n",
      "Epoch 126/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0307e-04 - val_loss: 0.0185\n",
      "Epoch 127/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4521e-04 - val_loss: 0.0184\n",
      "Epoch 128/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0342e-04 - val_loss: 0.0174\n",
      "Epoch 129/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5211e-04 - val_loss: 0.0202\n",
      "Epoch 130/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1848e-04 - val_loss: 0.0206\n",
      "Epoch 131/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0168\n",
      "Epoch 132/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0164\n",
      "Epoch 133/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0298\n",
      "Epoch 134/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0152\n",
      "Epoch 135/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0183\n",
      "Epoch 136/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0197\n",
      "Epoch 137/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0179\n",
      "Epoch 138/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0182\n",
      "Epoch 139/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0189\n",
      "Epoch 140/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0195\n",
      "Epoch 141/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0141\n",
      "Epoch 142/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0199\n",
      "Epoch 143/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0143\n",
      "Epoch 144/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0152\n",
      "Epoch 145/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0190\n",
      "Epoch 146/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0171\n",
      "Epoch 147/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0172\n",
      "Epoch 148/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0150\n",
      "Epoch 149/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0240\n",
      "Epoch 150/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 - val_loss: 0.0177\n",
      "Epoch 151/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0140\n",
      "Epoch 152/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 153/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0147\n",
      "Epoch 154/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0162\n",
      "Epoch 155/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0138\n",
      "Epoch 156/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0144\n",
      "Epoch 157/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4679e-04 - val_loss: 0.0166\n",
      "Epoch 158/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0165\n",
      "Epoch 159/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0140\n",
      "Epoch 160/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0135\n",
      "Epoch 161/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9364e-04 - val_loss: 0.0130\n",
      "Epoch 162/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5117e-04 - val_loss: 0.0167\n",
      "Epoch 163/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2326e-04 - val_loss: 0.0134\n",
      "Epoch 164/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5915e-04 - val_loss: 0.0138\n",
      "Epoch 165/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9404e-04 - val_loss: 0.0141\n",
      "Epoch 166/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7991e-04 - val_loss: 0.0143\n",
      "Epoch 167/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1109e-04 - val_loss: 0.0153\n",
      "Epoch 168/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3995e-04 - val_loss: 0.0152\n",
      "Epoch 169/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2183e-04 - val_loss: 0.0137\n",
      "Epoch 170/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2296e-04 - val_loss: 0.0151\n",
      "Epoch 171/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7509e-04 - val_loss: 0.0142\n",
      "Epoch 172/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1594e-04 - val_loss: 0.0147\n",
      "Epoch 173/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1377e-04 - val_loss: 0.0145\n",
      "Epoch 174/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0160e-04 - val_loss: 0.0147\n",
      "Epoch 175/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3197e-04 - val_loss: 0.0144\n",
      "Epoch 176/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2632e-04 - val_loss: 0.0137\n",
      "Epoch 177/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7330e-04 - val_loss: 0.0181\n",
      "Epoch 178/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0185\n",
      "Epoch 179/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0147\n",
      "Epoch 180/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0151\n",
      "Epoch 181/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0134\n",
      "Epoch 182/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4719e-04 - val_loss: 0.0151\n",
      "Epoch 183/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7843e-04 - val_loss: 0.0133\n",
      "Epoch 184/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8921e-04 - val_loss: 0.0149\n",
      "Epoch 185/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8152e-04 - val_loss: 0.0141\n",
      "Epoch 186/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4818e-04 - val_loss: 0.0145\n",
      "Epoch 187/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9297e-04 - val_loss: 0.0149\n",
      "Epoch 188/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8636e-04 - val_loss: 0.0158\n",
      "Epoch 189/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1119e-04 - val_loss: 0.0135\n",
      "Epoch 190/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1678e-04 - val_loss: 0.0139\n",
      "Epoch 191/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1854e-04 - val_loss: 0.0156\n",
      "Epoch 192/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6184e-04 - val_loss: 0.0176\n",
      "Epoch 193/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0151\n",
      "Epoch 194/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5983e-04 - val_loss: 0.0142\n",
      "Epoch 195/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0530e-04 - val_loss: 0.0146\n",
      "Epoch 196/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9896e-04 - val_loss: 0.0135\n",
      "Epoch 197/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7425e-04 - val_loss: 0.0152\n",
      "Epoch 198/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3426e-04 - val_loss: 0.0163\n",
      "Epoch 199/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0503e-04 - val_loss: 0.0164\n",
      "Epoch 200/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7324e-04 - val_loss: 0.0148\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, activation='relu', input_shape=(X_train.shape[1],)))  # เลเยอร์แรก\n",
    "model.add(Dense(15, activation='relu'))  # เลเยอร์ที่สอง\n",
    "model.add(Dense(1))  # เลเยอร์สุดท้าย (สำหรับการทำนาย)\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "model.compile(optimizer= Adam(learning_rate = 0.075 ), loss='mean_squared_error')\n",
    "\n",
    "# ดูภาพรวมของโครงสร้างโมเดล\n",
    "model.summary()\n",
    "\n",
    "# ฝึกโมเดล\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=20, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 4: ทำนายโดยใช้ชุดทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขั้นตอนที่ 5: ประเมินผลโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# แสดงผลลัพธ์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.023089276475534527\n",
      "R-squared (R^2): 0.8238070576841878\n",
      "\n",
      "Layer 1 Weights:\n",
      "[[-1.84213687e-02 -1.65179640e-01 -4.60181594e-01 -7.13467538e-01\n",
      "  -3.28511208e-01 -3.25937986e-01  7.32658565e-01 -1.11107595e-01\n",
      "   2.63362288e-01  3.52476150e-01 -3.71280700e-01 -1.30663216e+00\n",
      "   1.36473453e+00 -6.39526665e-01 -2.72651285e-01  4.83020484e-01\n",
      "  -6.61648452e-01 -5.66402853e-01 -2.00044736e-01 -7.57696450e-01\n",
      "   3.05406660e-01 -3.53928715e-01 -2.65014112e-01 -5.86241717e-03\n",
      "  -1.11849438e-02]\n",
      " [ 3.36547077e-01  5.44558227e-01 -2.47433960e-01 -9.42363560e-01\n",
      "  -2.57235616e-01 -3.76794338e-01 -7.15035260e-01  4.08794016e-01\n",
      "   6.05535090e-01 -3.88874382e-01  5.70554495e-01 -2.04174846e-01\n",
      "   3.77904534e-01 -1.76780045e-01 -8.61847326e-02  4.28000391e-01\n",
      "  -4.73503083e-01  3.74428004e-01  1.93853900e-02 -3.25296044e-01\n",
      "  -5.66561818e-01  8.87272134e-02  1.94184229e-01 -1.09685731e+00\n",
      "  -3.48247774e-02]\n",
      " [-7.93733001e-02  2.95048058e-01 -3.85372072e-01 -2.52066225e-01\n",
      "  -2.32488096e-01  1.99889600e-01 -3.61484617e-01 -5.63729584e-01\n",
      "   2.12495252e-01 -1.37974545e-01  9.48547870e-02 -4.78025585e-01\n",
      "  -7.39440799e-01 -8.00996363e-01 -6.15110397e-01 -3.85713995e-01\n",
      "  -5.10564782e-02  2.60383576e-01  8.91285390e-02 -1.58665270e-01\n",
      "  -5.63286424e-01  6.56629503e-01 -7.22475886e-01 -5.29004753e-01\n",
      "  -1.57391831e-01]\n",
      " [-1.72584075e-02  1.97731659e-01  9.55869794e-01 -4.17500407e-01\n",
      "  -2.06922606e-01 -4.02654916e-01 -3.01480800e-01 -1.01409234e-01\n",
      "  -3.67006153e-01 -1.85257718e-01  1.42070696e-01 -3.10872555e-01\n",
      "  -3.68972987e-01  9.82104689e-02 -1.97526049e-02 -1.92618594e-02\n",
      "  -2.74853349e-01 -3.58552545e-01 -6.27262443e-02 -2.90518969e-01\n",
      "  -6.69893503e-01  3.79546255e-01 -5.00407517e-01 -8.30943882e-01\n",
      "  -1.95331320e-01]\n",
      " [ 2.01242298e-01  1.95490807e-01  1.29151747e-01 -4.58174676e-01\n",
      "  -8.51968944e-01 -2.28055120e-01  1.85839519e-01  1.93813741e-01\n",
      "   2.08939746e-01 -1.55925136e-02  2.47008175e-01  1.23882204e-01\n",
      "   4.03699815e-01  2.29520798e-02  5.03197432e-01  3.45822334e-01\n",
      "  -1.16354618e-02  1.22052029e-01 -4.50109124e-01  3.49160582e-01\n",
      "  -5.93874268e-02  2.89988369e-01 -8.72076899e-02 -1.14077044e+00\n",
      "  -1.74393594e-01]\n",
      " [-1.35306986e-02 -6.90402389e-01 -2.92234540e-01 -3.49147409e-01\n",
      "  -1.05349883e-01 -5.47228813e-01 -8.52340981e-02 -2.31840074e-01\n",
      "  -8.50819498e-02 -8.10266435e-01  3.30138862e-01  1.76852942e-01\n",
      "   1.44448966e-01 -5.59804380e-01 -4.54786718e-01  6.46745980e-01\n",
      "  -8.00042272e-01  3.89376521e-01 -9.26654320e-03 -7.65548274e-02\n",
      "  -1.21274516e-01  1.40260577e-01 -1.48465008e-01  1.62442960e-02\n",
      "  -6.72886133e-01]\n",
      " [ 3.12973738e-01 -3.51836354e-01 -4.25997339e-02  2.34183982e-01\n",
      "   5.04542768e-01 -2.49562696e-01  5.14737785e-01 -1.25884749e-02\n",
      "  -2.06090942e-01  7.66203582e-01  5.82993031e-01  1.87772736e-02\n",
      "   1.18192323e-01 -2.98363060e-01  7.83790231e-01  1.97343633e-01\n",
      "   3.75993587e-02  4.35098529e-01  6.55950010e-01  1.79349497e-01\n",
      "   6.09872103e-01  4.82590944e-01 -2.52678424e-01  2.42353931e-01\n",
      "   8.58138949e-02]\n",
      " [-5.25106609e-01 -5.05840108e-02  3.54930311e-01 -4.95288491e-01\n",
      "   5.53691573e-02 -6.25706911e-01 -3.67108770e-02 -3.37911963e-01\n",
      "  -2.05496140e-03 -8.23952973e-01 -3.73502612e-01 -6.59480572e-01\n",
      "   5.40392883e-02 -1.64917305e-01  1.68628663e-01 -4.29055020e-02\n",
      "   5.00474453e-01  3.42216790e-01 -5.88097930e-01 -2.62241125e-01\n",
      "  -6.16956115e-01 -7.99852610e-01 -4.89739984e-01 -1.99650582e-02\n",
      "   3.59418765e-02]\n",
      " [-3.99973035e-01 -1.21931739e-01  5.99804282e-01 -2.04668224e-01\n",
      "  -1.03231080e-01  1.31990030e-01 -5.51501691e-01  2.46573035e-02\n",
      "   7.76130080e-01  7.21687451e-02  3.19950759e-01 -6.10106051e-01\n",
      "  -1.22204728e-01 -1.68464724e-02 -7.19469965e-01 -3.72131646e-01\n",
      "  -6.11738443e-01 -1.22571379e-01 -5.29013574e-02 -4.39902753e-01\n",
      "  -2.82757521e-01 -5.49685061e-01 -6.26178443e-01 -9.82622802e-01\n",
      "  -2.14865834e-01]\n",
      " [ 1.05056480e-01  1.64953664e-01  9.80750382e-01 -3.75591010e-01\n",
      "   1.36784673e-01  1.81082770e-01  1.35865465e-01  1.49215266e-01\n",
      "  -1.57525688e-01  5.84887005e-02 -4.53606516e-01  4.26520437e-01\n",
      "   2.10120097e-01  2.02150986e-01  1.68099269e-01  4.12832052e-01\n",
      "   1.71619147e-01  3.83531749e-01 -2.14592203e-01  5.92717119e-02\n",
      "   3.53763044e-01  1.82252735e-01  4.21182543e-01 -1.69812009e-01\n",
      "  -2.25183442e-01]\n",
      " [-4.76395786e-01  3.68273258e-01  3.60960439e-02 -2.85030633e-01\n",
      "  -9.25857350e-02 -2.83947110e-01 -5.08647382e-01  2.07208067e-01\n",
      "   3.16183358e-01 -4.07904834e-01  1.96931347e-01  2.35729925e-02\n",
      "   2.85837889e-01 -9.88161564e-02 -2.46135771e-01 -2.92028576e-01\n",
      "  -4.53557611e-01 -1.56230837e-01 -4.39292639e-01 -3.97398233e-01\n",
      "  -2.95279741e-01 -3.87079984e-01 -2.93230929e-04  1.85211524e-01\n",
      "  -5.40924311e-01]\n",
      " [-6.16302311e-01  7.55134463e-01  8.79453778e-01 -5.98012269e-01\n",
      "  -5.95262527e-01 -3.21227729e-01 -6.26884043e-01 -7.75508344e-01\n",
      "   6.20975852e-01 -1.33826062e-01  8.75062719e-02 -8.02466094e-01\n",
      "  -1.07699084e+00 -1.06601268e-01  1.47232097e-02 -5.42659283e-01\n",
      "  -3.58868569e-01 -1.29161686e-01 -1.72609940e-01 -5.81469573e-02\n",
      "  -2.19827384e-01 -3.36203992e-01 -2.82606900e-01 -2.26065621e-01\n",
      "  -2.55727559e-01]\n",
      " [ 6.90405443e-02 -5.74764073e-01 -2.07739770e-01 -4.81822580e-01\n",
      "  -5.31997323e-01  1.15550086e-02  4.58549768e-01  9.40019414e-02\n",
      "   4.73230064e-01 -1.10506169e-01 -9.41397771e-02  1.14500552e-01\n",
      "  -7.02608470e-03 -4.36100304e-01  2.81120747e-01 -4.64376718e-01\n",
      "  -1.29131973e-01 -4.09705907e-01 -2.35681117e-01 -3.21575284e-01\n",
      "  -6.00947261e-01  3.51223975e-01 -7.92890549e-01 -3.68968844e-01\n",
      "  -8.83681998e-02]\n",
      " [ 4.44242448e-01 -1.57910004e-01 -6.15970850e-01 -2.56417334e-01\n",
      "  -6.76148713e-01 -6.70610726e-01  5.83493151e-02  2.43657187e-01\n",
      "   5.33691049e-01 -4.06661024e-03 -3.27459946e-02 -5.02073824e-01\n",
      "   1.86252832e-01 -1.64008811e-02 -2.06794336e-01  1.45864516e-01\n",
      "  -7.29971290e-01  6.46212772e-02 -3.93780082e-01 -5.39251506e-01\n",
      "  -4.56679702e-01  1.07907973e-01 -1.83732435e-02 -2.39944592e-01\n",
      "  -1.94995701e-01]\n",
      " [ 1.35642201e-01 -3.29159647e-01 -4.82313871e-01 -1.73824981e-01\n",
      "  -3.40173870e-01  1.21047586e-01  3.07770133e-01  5.77358782e-01\n",
      "   4.77430075e-01 -3.41714740e-01 -2.96171069e-01  4.52292323e-01\n",
      "   1.40519841e-02  1.66259661e-01  3.74938041e-01 -3.18258673e-01\n",
      "  -1.08009741e-01 -1.16530657e-02 -3.97535980e-01  6.54794335e-01\n",
      "   3.07737231e-01  2.92009175e-01 -2.02994347e-01 -4.92925882e-01\n",
      "  -5.26686609e-02]\n",
      " [ 3.68380696e-01 -2.20185161e-01 -2.23907635e-01 -3.65211815e-01\n",
      "  -2.58163303e-01 -2.79127985e-01  2.98467249e-01  3.73817310e-02\n",
      "   5.21565616e-01 -2.69911826e-01  5.54903746e-01  3.43911976e-01\n",
      "   5.81266224e-01 -2.72316307e-01  6.40361011e-01 -1.95205167e-01\n",
      "  -6.06363118e-02 -5.18341720e-01 -1.86215546e-02  2.24401236e-01\n",
      "  -2.07730144e-01 -1.87715590e-01 -1.03007145e-01 -2.95928866e-01\n",
      "  -9.79856867e-03]\n",
      " [ 2.50796765e-01  1.74770337e-02 -3.19789052e-01 -7.48589277e-01\n",
      "  -3.29266548e-01 -1.41900599e-01 -3.18616658e-01  1.82751417e-01\n",
      "   5.42908549e-01 -2.79823899e-01  1.29312962e-01 -3.38391691e-01\n",
      "   4.69706953e-01  3.96182925e-01 -2.73078680e-02  1.10674664e-01\n",
      "  -5.35334766e-01  1.63326442e-01 -6.62928820e-02 -3.77340823e-01\n",
      "  -3.05990189e-01  3.77184272e-01 -1.19644314e-01 -6.74271524e-01\n",
      "  -1.68869048e-01]\n",
      " [ 5.49804449e-01 -2.15976268e-01 -1.16779590e+00 -6.53194427e-01\n",
      "   1.95653155e-01 -5.58215439e-01 -3.96421812e-02  6.00404918e-01\n",
      "   2.17745826e-01 -5.63739896e-01  1.08601317e-01  2.18734279e-01\n",
      "   3.73780251e-01  3.81666839e-01  2.29225397e-01  1.19027138e-01\n",
      "  -4.99843240e-01 -6.30164087e-01 -4.63175416e-01  5.61088264e-01\n",
      "  -5.15126698e-02  7.15539336e-01  4.84936908e-02 -3.71794194e-01\n",
      "  -4.55850005e-01]\n",
      " [ 2.48787791e-01  6.58765972e-01 -4.69085276e-01 -4.47531253e-01\n",
      "  -3.64116073e-01  2.79237241e-01  3.21604580e-01  4.07179177e-01\n",
      "   1.71218351e-01  1.10746279e-01 -9.59500149e-02  6.64478779e-01\n",
      "   4.44800884e-01  3.37061524e-01  1.46221444e-01 -8.19162369e-01\n",
      "  -1.76136091e-01  1.43933266e-01 -1.96928103e-02  2.27712005e-01\n",
      "  -3.04198235e-01  6.76799953e-01 -2.68872768e-01 -6.80822313e-01\n",
      "  -4.22768652e-01]\n",
      " [ 1.72962651e-01  5.51864207e-01 -1.40709817e-01 -3.51744324e-01\n",
      "  -3.28111500e-01 -8.21168721e-02  2.64782786e-01  5.91232300e-01\n",
      "   1.45842969e-01 -3.07314962e-01 -3.98833930e-01  7.51660466e-01\n",
      "   5.18308103e-01 -8.87044907e-01 -6.23054206e-01  2.50258446e-01\n",
      "  -7.40362644e-01 -2.27950156e-01  1.63910106e-01 -3.79980475e-01\n",
      "  -5.71747005e-01  7.07286417e-01 -3.95139009e-01 -2.89925337e-01\n",
      "  -1.95804715e-01]\n",
      " [ 9.37684551e-02 -2.01306958e-02  1.32324442e-01 -4.68552345e-03\n",
      "  -4.04278398e-01 -3.86976331e-01  5.84316514e-02  2.02569380e-01\n",
      "   2.22176999e-01 -1.61319017e-01 -8.22780132e-02  4.69183385e-01\n",
      "   2.64189333e-01 -7.99148083e-02 -7.23648131e-01  5.50570488e-01\n",
      "  -6.72288179e-01 -5.44383109e-01 -1.12542965e-01 -2.99108028e-01\n",
      "  -8.57176930e-02 -9.06183571e-02 -3.01172920e-02 -1.45591393e-01\n",
      "  -1.97321683e-01]\n",
      " [ 1.07344903e-01 -3.71602364e-02 -1.12426698e-01 -3.48600060e-01\n",
      "  -6.57888889e-01 -4.74102139e-01  3.91271025e-01  2.18400583e-01\n",
      "   1.91843748e-01  7.58810461e-01  1.73880845e-01  1.04216710e-01\n",
      "   2.10757941e-01  8.68018806e-01  7.18623623e-02  3.07457969e-02\n",
      "  -2.42345080e-01  2.47339278e-01  3.56119305e-01  6.20795131e-01\n",
      "   5.63608587e-01  3.13797385e-01  6.92898333e-02  3.47780794e-01\n",
      "  -1.23026982e-01]\n",
      " [ 2.06838325e-01 -9.05260324e-01  3.17947417e-01 -8.49384606e-01\n",
      "   1.11746475e-01 -1.63162872e-02  6.49737060e-01 -3.23353074e-02\n",
      "   4.31988657e-01  4.07117531e-02 -7.50330612e-02 -4.46135074e-01\n",
      "   6.40627086e-01 -8.89308229e-02 -3.85386497e-01  5.84628224e-01\n",
      "  -2.96359986e-01 -5.35621285e-01 -6.95914865e-01 -9.25578237e-01\n",
      "   9.87404436e-02  6.59046918e-02 -2.77687639e-01  3.96236241e-01\n",
      "  -5.65758407e-01]\n",
      " [ 1.44604638e-01 -9.73348141e-01 -8.01769793e-01 -2.42731526e-01\n",
      "   2.07890302e-01  9.64816868e-01 -1.53323159e-01  3.23850781e-01\n",
      "   6.81137681e-01 -2.88905859e-01  7.79660344e-02  3.94884124e-02\n",
      "   4.43890452e-01 -6.46209598e-01  6.19893909e-01  5.05771518e-01\n",
      "  -6.38027936e-02 -5.31552553e-01 -1.06997162e-01  4.78592604e-01\n",
      "  -1.46801189e-01  8.87857556e-01  1.72855243e-01  3.33934247e-01\n",
      "  -8.33882913e-02]\n",
      " [-2.48028487e-01 -3.09196293e-01 -2.42999285e-01 -5.71085274e-01\n",
      "   4.42705266e-02 -4.27698821e-01 -5.42643368e-01 -5.72006643e-01\n",
      "   6.56930327e-01 -1.79111157e-02 -1.88740075e-01 -5.84556460e-01\n",
      "  -8.86598229e-01  2.10517421e-01 -8.73828232e-01 -1.69152394e-02\n",
      "  -1.68690607e-01 -2.58111894e-01 -6.40558600e-01 -1.35739133e-01\n",
      "  -1.36783093e-01  1.08401954e-01 -2.99958706e-01  4.38046575e-01\n",
      "  -3.84435862e-01]\n",
      " [ 5.12689769e-01  7.73756430e-02  2.81542331e-01 -1.22898825e-01\n",
      "  -4.71536785e-01 -9.41301167e-01  1.50422454e-01  5.45533180e-01\n",
      "   4.00776595e-01 -2.75874615e-01 -7.26389945e-01  4.41889942e-01\n",
      "   1.26933396e-01 -4.83790815e-01  3.66257399e-01 -4.83788624e-02\n",
      "  -2.29628935e-01 -6.51545346e-01 -5.30591421e-02  3.08457673e-01\n",
      "   5.99212870e-02 -3.27488065e-01 -5.53602159e-01 -6.20657742e-01\n",
      "   9.59630981e-02]\n",
      " [ 3.19459885e-01  1.16875730e-01  3.01340580e-01  3.76836181e-01\n",
      "  -5.12720585e-01 -1.75659850e-01  2.81351417e-01  3.93184662e-01\n",
      "   2.18759850e-01 -7.30112731e-01  3.61411035e-01  1.08122420e+00\n",
      "   9.90322232e-02 -3.27753842e-01 -5.47229290e-01  1.80958018e-01\n",
      "  -6.06059968e-01 -8.66870761e-01  1.92319881e-02 -2.18005627e-01\n",
      "  -3.70531678e-02 -1.40596271e-01 -5.32894254e-01 -3.53302509e-01\n",
      "  -6.91905260e-01]\n",
      " [-7.62961656e-02 -5.61627030e-01 -7.19570443e-02 -6.71259388e-02\n",
      "  -4.78912354e-01 -2.42707148e-01 -1.92522984e-02  3.34753662e-01\n",
      "  -9.53035727e-02 -7.01652646e-01  3.41325879e-01 -6.47215903e-01\n",
      "   9.37480807e-01 -7.57262632e-02  7.57758856e-01  6.56930685e-01\n",
      "  -2.79323816e-01 -1.06090680e-01 -7.21515536e-01 -7.79060900e-01\n",
      "   6.15604460e-01  3.93448234e-01 -1.32349148e-01  7.67513454e-01\n",
      "  -2.36774981e-01]\n",
      " [ 6.34351373e-01 -2.85903007e-01  5.26445687e-01 -4.95211869e-01\n",
      "  -3.29979986e-01 -6.54330969e-01  3.80047381e-01  1.29159400e-02\n",
      "   5.89616954e-01 -4.48262542e-01  3.40881586e-01 -3.11603099e-01\n",
      "  -5.15379131e-01 -3.48854452e-01 -3.79954696e-01 -2.54394919e-01\n",
      "  -7.54340649e-01 -6.40360231e-04 -9.58113819e-02 -5.26436925e-01\n",
      "  -2.57589012e-01 -2.38004535e-01 -4.31386828e-01 -5.92484295e-01\n",
      "  -4.21920806e-01]\n",
      " [ 3.24998260e-01 -3.92506421e-01  7.39757597e-01 -4.20183420e-01\n",
      "  -2.23461520e-02 -5.31663537e-01  6.13919973e-01  4.37484831e-01\n",
      "   7.27243602e-01  9.75533351e-02 -6.60835654e-02 -3.06931496e-01\n",
      "   3.24097578e-03 -2.91858017e-01 -6.86932147e-01  1.73029006e-02\n",
      "  -6.41755462e-01 -2.01592699e-01 -3.43098611e-01 -7.65345097e-01\n",
      "   7.38636181e-02  1.15152918e-01 -4.16405886e-01 -8.10119510e-02\n",
      "  -2.03322291e-01]]\n",
      "Biases:\n",
      "[-0.7908844   0.21597205  0.6209004  -0.44632223 -0.08440994 -0.18256319\n",
      " -0.9165329  -0.39652514  0.9203853   0.21781832 -1.1879526  -0.36843827\n",
      "  0.11577917  0.2441787  -0.27546874 -0.0604883  -0.61485386  0.22577238\n",
      " -0.30406737 -0.21753755 -1.7258077   0.36401606 -0.9641473  -0.02720837\n",
      " -0.3290084 ]\n",
      "Layer 2 Weights:\n",
      "[[-0.15071045 -0.10921386 -0.10005996  0.03865765 -0.16556264 -0.63458306\n",
      "  -0.51114947 -0.34520835 -0.03928752 -0.01870895 -0.19009626 -0.8010007\n",
      "  -0.13179624 -0.29658893 -0.30816177]\n",
      " [-0.698102   -0.05775727  0.3129402   0.22068284 -0.2616786  -0.61183083\n",
      "  -0.6151525  -0.49501613 -0.610889   -0.27069262 -0.26384804 -0.11572048\n",
      "  -0.48033792 -0.03286478 -0.6775834 ]\n",
      " [-0.6884109   0.16206023 -0.21502829  0.1203943  -0.67974836 -0.0593246\n",
      "  -0.7590436  -0.27941972 -0.56060296 -0.27234137  0.54195166 -0.08370765\n",
      "  -0.11929151 -0.40869105 -0.4047651 ]\n",
      " [-0.16767433 -0.00512653  0.35221055  0.01744024 -0.4904817  -0.5360935\n",
      "  -0.38620335 -0.30629304 -0.30168223 -0.04285496  0.11241848 -0.31465557\n",
      "  -0.14675514 -0.46875256 -0.66929936]\n",
      " [-0.520325    0.00939058 -0.6359149  -0.6991894  -0.6917413  -0.40815914\n",
      "  -0.74384016  0.47518098 -0.23211734 -0.49101952  0.01195694 -0.80545366\n",
      "   0.07124723  0.60675967 -0.30188602]\n",
      " [-0.16044839  0.02111551  0.03882949 -0.47103724 -0.47375956 -0.17735069\n",
      "  -0.3566977  -0.6733467  -0.5557554  -0.41810578 -0.19181463 -0.7901838\n",
      "   0.0041343   0.17034315 -0.15530741]\n",
      " [-0.16859043  0.1715694   0.04577784 -0.08879624 -0.5105314  -0.71022654\n",
      "  -0.24243976 -0.46061584 -0.27451083 -0.241597   -0.04966189 -0.7171359\n",
      "   0.18200716  0.33844504 -0.3543628 ]\n",
      " [-0.41447634 -0.17777725  0.04820613  0.10102482 -0.02794153 -0.37978423\n",
      "  -0.28247997 -0.02744852 -0.08470575 -0.23166086 -0.11247373 -0.7145643\n",
      "  -0.11076804 -0.27558163 -0.09491736]\n",
      " [-0.32066816  0.27740782  0.36960855 -0.3008149   0.2691425  -0.7586666\n",
      "   0.03712765 -0.5934617  -0.18473005 -0.6541979   0.24990289 -0.34061173\n",
      "  -0.20813084 -0.7912785  -0.34883562]\n",
      " [-0.27682418  0.22326872  0.03498612 -0.6028239  -0.23728052 -0.5617371\n",
      "  -0.19255775  0.13844378 -0.44089893 -0.4974031  -0.4680037  -0.08280462\n",
      "   0.09810487  0.06635668 -0.8302835 ]\n",
      " [-0.02079037 -0.15275337 -0.23953485  0.1654534   0.06627876 -0.21690957\n",
      "  -0.48048386 -0.10878782 -0.15611656  0.20088814 -0.28957272 -0.5854764\n",
      "   0.06295431 -0.03654363 -0.5727027 ]\n",
      " [-0.4697184   0.25894374  0.12851392 -0.3778996  -0.71051204 -0.27820578\n",
      "  -0.18384404 -0.28947377 -0.12938634 -0.14801772 -0.02131953 -0.4735929\n",
      "  -0.26960498 -0.07244118 -0.38346627]\n",
      " [-0.18238607  0.27236962 -0.06361753  0.05558493 -0.4616369  -0.2274311\n",
      "  -0.5373445  -0.7425408  -0.04469872 -0.5868333  -0.10456243 -0.80269945\n",
      "  -0.5551987   0.12844051 -0.497346  ]\n",
      " [-0.42414004  0.09250282  0.34627137 -0.23399602 -0.60015804 -0.5556213\n",
      "   0.33780143  0.19320989 -0.75915617 -0.3498115   0.0974399  -0.15057717\n",
      "  -0.46691298  0.04814841 -0.6919983 ]\n",
      " [-0.09058286  0.22627601 -0.2096835   0.10962641 -0.6861132  -0.49847656\n",
      "  -0.35937208  0.09051485 -0.10201292 -0.7707954   0.11510783 -0.57612884\n",
      "  -0.02168648  0.12023467 -0.28573975]\n",
      " [-0.79731673  0.06716006 -0.23579897 -0.7364192  -0.31664047 -0.1884336\n",
      "  -0.62629086 -0.65611565  0.11107048 -0.5496325   0.46942204 -0.24538569\n",
      "  -0.2937851   0.20685256 -0.4987811 ]\n",
      " [-0.12979817 -0.2662997   0.068814   -0.41592455 -0.4946133  -0.22013447\n",
      "  -0.46766913 -0.13141926 -0.6646262  -0.3548395  -0.61605924 -0.43157715\n",
      "   0.09795545 -0.35498083 -0.7932886 ]\n",
      " [-0.72955066  0.1941698  -0.03886704 -0.40491182 -0.38114023 -0.17793484\n",
      "   0.5961657   0.22628514 -0.44091803 -0.19682829 -0.48790205 -0.62467915\n",
      "  -0.49502122  0.24175718 -0.09686592]\n",
      " [-0.640597   -0.34708142  0.12527317 -0.41462472  0.02978628 -0.10608877\n",
      "  -0.29056016  0.02273068  0.02817388 -0.45116186 -0.5232608  -0.76145256\n",
      "  -0.6004929   0.62416553 -0.47028926]\n",
      " [-0.15139318  0.12361515  0.04425368 -0.49317977 -0.00921362 -0.11037442\n",
      "  -0.31550774  0.48835126 -0.1989978  -0.24386305 -0.0101908  -0.3181466\n",
      "  -0.36208546 -0.36074668 -0.48084876]\n",
      " [-0.35264087 -0.32029945 -0.48284018  0.25248295  0.01087665 -0.38076085\n",
      "  -0.35557714 -0.1818827  -0.3190918   0.11130813 -0.67123884 -0.14529884\n",
      "  -0.31328225 -0.529707   -0.8126566 ]\n",
      " [-0.5845308   0.37329626 -0.00632496 -0.7426076  -0.37090844 -0.2332576\n",
      "  -0.0043242   0.10854565 -0.23498923 -0.70695764 -0.04534268 -0.5864427\n",
      "  -0.53092706 -0.2686299  -0.64777684]\n",
      " [-0.21248068 -0.47022277 -0.02718675 -0.4780578  -0.50055474 -0.30350646\n",
      "  -0.0147502  -0.6752426  -0.6833247  -0.28604403  0.048449   -0.18517973\n",
      "  -0.5893034  -0.39814827 -0.07775979]\n",
      " [-0.18358217  0.28717765 -0.55049366 -0.4699589  -0.3607152   0.031358\n",
      "  -0.21791326 -0.02165788 -0.39164674 -0.573489   -0.01867196 -0.6972585\n",
      "   0.20197171  0.04008414 -0.7991069 ]\n",
      " [-0.2361348  -0.04018064 -0.19260594 -0.33820328  0.07167049 -0.3681825\n",
      "  -0.13038382  0.3021147  -0.2913046  -0.7512252  -0.20260686 -0.7646535\n",
      "  -0.02693154  0.08158367 -0.4069249 ]]\n",
      "Biases:\n",
      "[-0.4347374   0.907256    0.528723   -0.3211351  -0.20944914 -0.3119322\n",
      " -0.1786514  -0.30251834 -0.22511043 -0.4225068   0.18217675 -0.44783658\n",
      " -0.04003183  0.79489094 -0.45040658]\n",
      "Layer 3 Weights:\n",
      "[[-0.14669003]\n",
      " [ 0.15086456]\n",
      " [ 0.09419313]\n",
      " [ 0.05314428]\n",
      " [-0.03970698]\n",
      " [-0.26321903]\n",
      " [-0.02308558]\n",
      " [-0.04351923]\n",
      " [-0.10967732]\n",
      " [ 0.04141325]\n",
      " [ 0.06205185]\n",
      " [ 0.34292814]\n",
      " [ 0.05749128]\n",
      " [ 0.04360038]\n",
      " [ 0.17584729]]\n",
      "Biases:\n",
      "[2.0253856]\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Squared Error (MSE): {mse}')  # ค่าความคลาดเคลื่อนเฉลี่ย\n",
    "print(f'R-squared (R^2): {r2}')  # ค่าความแม่นยำของโมเดล\n",
    "print('')\n",
    "\n",
    "# แสดงค่า weights ของทุกเลเยอร์ในโมเดล ANN\n",
    "for i, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()  # ดึงค่า weights ของเลเยอร์\n",
    "    print(f\"Layer {i + 1} Weights:\")\n",
    "    print(weights[0])  # ค่า weights\n",
    "    print(\"Biases:\")\n",
    "    print(weights[1])  # ค่า biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# กราฟแสดงผล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# สร้างกราฟแสดงการฝึกโมเดล\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # Loss ในชุดฝึก\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')  # Loss ในชุดทดสอบ\n",
    "plt.xlabel('Epochs')  # ชื่อแกน X\n",
    "plt.ylabel('Loss')  # ชื่อแกน Y\n",
    "plt.legend()  # เพิ่มคำอธิบายกราฟ\n",
    "plt.show()  # แสดงกราฟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
